{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstring\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwordcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m WordCloud\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "nltk.download('all',quiet=True)\n",
    "from PIL import Image\n",
    "\n",
    "#Model libraries\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mounting drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Capstone Projects /Twitter Sentiment Analysis/Coronavirus Tweets.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Assigning variable\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_orignal\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/content/drive/MyDrive/Colab Notebooks/Capstone Projects /Twitter Sentiment Analysis/Coronavirus Tweets.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mlatin-1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Capstone Projects /Twitter Sentiment Analysis/Coronavirus Tweets.csv'"
     ]
    }
   ],
   "source": [
    "#Assigning variable\n",
    "df_orignal=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Capstone Projects /Twitter Sentiment Analysis/Coronavirus Tweets.csv', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying data to preserve orignal file\n",
    "df1=df_orignal.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking Head\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking info\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking Columns\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For sentiment analysis we only want tweet and sentiment Features\n",
    "df=df1[['OriginalTweet','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stastastical analysis of dataset\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking Unique values\n",
    "df.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking Shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check duplicate entries\n",
    "len(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"OriginalTweet\"] = df[\"OriginalTweet\"].str.lower()\n",
    "df['OriginalTweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OriginalTweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OriginalTweet'] = df['OriginalTweet'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_tweets\"] = df['OriginalTweet'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweets'] = df['clean_tweets'].str.replace(\"[^a-zA-Z#//]\",\" \")\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweets'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Stop-words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove stopwords and tokenize\n",
    "def remove_stopwords(text):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweets']= df['clean_tweets'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.clean_tweets[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for stemming\n",
    "def stemming(text):    \n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return (\" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed'] = df['clean_tweets'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result\n",
    "df.stemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "df['lemmed'] = df['clean_tweets'].apply(lambda x: [lemmatizer.lemmatize(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count = df['Sentiment'].value_counts().reset_index()\n",
    "sentiment_count.columns = ['Sentiment','count']\n",
    "sentiment_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "ax = sns.barplot(x=\"Sentiment\", y='count', data=sentiment_count)\n",
    "ax.set_title(\"Proportion of Sentiment\", fontsize=20)\n",
    "ax.set_xlabel(\"Sentiment\", fontsize=20)\n",
    "ax.set_ylabel('count', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing values\n",
    "replace_values = {\"Sentiment\":{'Extremely Negative':'Negative', 'Extremely Positive':'Positive'}}\n",
    "df = df.replace(replace_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count1 = df['Sentiment'].value_counts().reset_index()\n",
    "sentiment_count1.columns = ['Sentiment','count']\n",
    "sentiment_count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the piechart for Sentiments distribution\n",
    "sentiment_count1 = df['Sentiment'].value_counts().to_list()\n",
    "labels=['Positive','Negative','Netural']\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.pie(x=sentiment_count1,explode=[0.04,0.04,0.1],shadow= True,labels=labels,autopct=\"%.2f%%\",radius=1.1)\n",
    "plt.title(\"Proportion Of Sentiments\", fontsize=20)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp_list'] = df['clean_tweets'].apply(lambda x:str(x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "top = Counter([item for sublist in df['temp_list'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating the sentiments for word cloud \n",
    "neutral = pd.DataFrame(df[['stemmed','lemmed']] [df['Sentiment'] == 'Neutral'])\n",
    "positive = pd.DataFrame(df[['stemmed','lemmed']]  [df['Sentiment'] == 'Positive'])\n",
    "negative = pd.DataFrame(df[['stemmed','lemmed']]  [df['Sentiment'] == 'Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(\"/content/drive/MyDrive/Colab Notebooks/Capstone Projects /Twitter Sentiment Analysis/toppng.com-transparent-background-twitter-logo-943x800.png\"))\n",
    "\n",
    "\n",
    "wc = WordCloud(background_color='white',mask = mask,contour_width=1,contour_color='steelblue')\n",
    "wc.generate(str(neutral['lemmed']))\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(wc,interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating word cloud for positive sentiments\n",
    "wc.generate(str(positive['lemmed']))\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating word cloud for negative sentiments\n",
    "wc.generate(str(negative['lemmed']))\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Assigning dependent and independent features\n",
    "\n",
    "X= df['lemmed']\n",
    "y=df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,stratify=y,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking shape of splitted data\n",
    "print(X_train.shape)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking splitted data\n",
    "print(X_train.head())\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words\n",
    "cv=CountVectorizer(binary=False,max_df=1.0,min_df=5,ngram_range=(1,2))\n",
    "cv_X_train=cv.fit_transform(X_train.astype(str).str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tv=TfidfVectorizer(use_idf=True,max_df=1.0,min_df=5,ngram_range=(1,2),sublinear_tf=True)\n",
    "tv_X_train=tv.fit_transform(X_train.astype(str).str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_test=cv.transform(X_test.astype(str).str.strip())\n",
    "tv_X_test=tv.transform(X_test.astype(str).str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initalizing the model\n",
    "lr_cv = LogisticRegression()\n",
    "parameters = dict(penalty=['l1', 'l2'],C=[100, 10, 1.0, 0.1, 0.01])\n",
    "\n",
    "#Hyperparameter tuning by GridserchCV\n",
    "logreg_Gcv=GridSearchCV(lr_cv,parameters,cv=15)\n",
    "\n",
    "#fitting the data to model\n",
    "logreg_Gcv.fit(cv_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted values\n",
    "pred_lr_cv = logreg_Gcv.predict(cv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy_lr_cv = accuracy_score(y_test,pred_lr_cv)\n",
    "print(\"Accuracy :\",(accuracy_lr_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report of Performance metrics\n",
    "label=['neutral','positive','negative']\n",
    "print(classification_report(y_test,pred_lr_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confussion matrix\n",
    "cf1= (confusion_matrix(y_test,pred_lr_cv))\n",
    "plt.figure(figsize=(8,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf1, annot=True, fmt=\".0f\",ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels', fontsize=15)\n",
    "ax.set_ylabel('Actual labels', fontsize=15)\n",
    "ax.set_title('Confusion Matrix (Logistic Regression with CV)', fontsize=20)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "dt_cv=DecisionTreeClassifier()\n",
    "\n",
    "#fitting the data to model\n",
    "dt_cv.fit(cv_X_train,y_train)\n",
    "\n",
    "#predicted values\n",
    "pred_dt_cv=dt_cv.predict(cv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "cv_score_dt_cv= cross_val_score(dt_cv,cv_X_train,y_train, cv=5)\n",
    "print(\"Accuracy: {}\" .format(np.mean(cv_score_dt_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report of Performance metrics\n",
    "label=['Neutral','Positive','Negative']\n",
    "print(classification_report(y_test,pred_dt_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confussion matrix\n",
    "cf2= (confusion_matrix(y_test,pred_dt_cv))\n",
    "plt.figure(figsize=(8,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf2, annot=True, fmt=\".0f\",ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels', fontsize=15)\n",
    "ax.set_ylabel('Actual labels', fontsize=15)\n",
    "ax.set_title('Confusion Matrix (Decision tree with CV)', fontsize=20)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "xgb_cv=XGBClassifier()\n",
    "\n",
    "#fitting the data to model\n",
    "xgb_cv.fit(cv_X_train,y_train)\n",
    "\n",
    "#predicted values\n",
    "pred_xgb_cv=xgb_cv.predict(cv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "cv_score_xgb_cv= cross_val_score(xgb_cv,cv_X_train,y_train, cv=5)\n",
    "print(\"Accuracy: {}\" .format(np.mean(cv_score_xgb_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report of Performance metrics\n",
    "label=['Neutral','Positive','Negative']\n",
    "print(classification_report(y_test,pred_xgb_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confussion matrix\n",
    "cf3= (confusion_matrix(y_test,pred_xgb_cv))\n",
    "plt.figure(figsize=(8,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf3, annot=True, fmt=\".0f\",ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels', fontsize=15)\n",
    "ax.set_ylabel('Actual labels', fontsize=15)\n",
    "ax.set_title('Confusion Matrix (XG-Boost with CV)', fontsize=20)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "knn = KNeighborsClassifier()\n",
    "param = {'n_neighbors': [1,2,3,4,5,6,7,8]}\n",
    "knn_cv = GridSearchCV(estimator=knn,param_grid=param)\n",
    "\n",
    "#fitting the data to model\n",
    "knn_cv.fit(cv_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted values\n",
    "pred_knn_cv = knn_cv.predict(cv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy_KNN = accuracy_score(y_test,pred_knn_cv)\n",
    "print(\"Accuracy :\",(accuracy_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report of Performance metrics\n",
    "label=['Neutral','Positive','Negative']\n",
    "print(classification_report(y_test,pred_knn_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confussion matrix\n",
    "cf4= (confusion_matrix(y_test,pred_knn_cv))\n",
    "plt.figure(figsize=(8,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf4, annot=True, fmt=\".0f\",ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels', fontsize=15)\n",
    "ax.set_ylabel('Actual labels', fontsize=15)\n",
    "ax.set_title('Confusion Matrix (KNN with CV)', fontsize=20)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "svm_cv = SVC()\n",
    "\n",
    "#fitting the data to model\n",
    "svm_cv.fit(cv_X_train,y_train)\n",
    "\n",
    "#prediction\n",
    "pred_svm_cv = svm_cv.predict(cv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy_svc = accuracy_score(y_test,pred_svm_cv)\n",
    "print(\"Accuracy :\",(accuracy_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report of Performance metrics\n",
    "label=['Neutral','Positive','Negative']\n",
    "print(classification_report(y_test,pred_svm_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confussion matrix\n",
    "cf5= (confusion_matrix(y_test,pred_svm_cv))\n",
    "plt.figure(figsize=(8,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf5, annot=True, fmt=\".0f\",ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels', fontsize=15)\n",
    "ax.set_ylabel('Actual labels', fontsize=15)\n",
    "ax.set_title('Confusion Matrix (SVM with CV)', fontsize=20)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "lr_tv=LogisticRegression()\n",
    "parameters = dict(penalty=['l1', 'l2'],C=[100, 10, 1.0, 0.1, 0.01])\n",
    "\n",
    "#Hyperparameter tuning by GridserchCV\n",
    "lr_tv_Gcv=GridSearchCV(lr_tv,parameters,cv=5)\n",
    "\n",
    "#fitting the data to model\n",
    "lr_tv_Gcv.fit(tv_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted values\n",
    "pred_lr_tv_Gcv = lr_tv_Gcv.predict(tv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr_tv_Gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb Cell 82\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y144sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Accuracy\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y144sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m accuracy_lr_Gcv \u001b[39m=\u001b[39m accuracy_score(y_test,pred_lr_tv_Gcv)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y144sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy :\u001b[39m\u001b[39m\"\u001b[39m,(accuracy_lr_Gcv))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "accuracy_lr_Gcv = accuracy_score(y_test,pred_lr_tv_Gcv)\n",
    "print(\"Accuracy :\",(accuracy_lr_Gcv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report of Performance metrics\n",
    "label=['Neutral','Positive','Negative']\n",
    "print(classification_report(y_test,pred_lr_tv_Gcv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confussion matrix\n",
    "cf1a= (confusion_matrix(y_test,pred_lr_tv_Gcv))\n",
    "plt.figure(figsize=(8,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf1a, annot=True, fmt=\".0f\",ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels', fontsize=15)\n",
    "ax.set_ylabel('Actual labels', fontsize=15)\n",
    "ax.set_title('Confusion Matrix (Logistic Regg with TF/IDF)', fontsize=20)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "dt_tv=DecisionTreeClassifier()\n",
    "\n",
    "#fitting the data to model\n",
    "dt_tv.fit(tv_X_train,y_train)\n",
    "\n",
    "#prediction\n",
    "pred_dt_tv=dt_tv.predict(tv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt_tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb Cell 87\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y152sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Accuracy\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y152sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cv_score_dt_tv\u001b[39m=\u001b[39m cross_val_score(dt_tv,tv_X_train,y_train, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y152sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m.\u001b[39mformat(np\u001b[39m.\u001b[39mmean(cv_score_dt_tv)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "cv_score_dt_tv= cross_val_score(dt_tv,tv_X_train,y_train, cv=5)\n",
    "print(\"Accuracy: {}\" .format(np.mean(cv_score_dt_tv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report of Performance metrics\n",
    "label=['Neutral','Positive','Negative']\n",
    "print(classification_report(y_test,pred_dt_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confussion matrix\n",
    "cf2a= (confusion_matrix(y_test,pred_dt_tv))\n",
    "plt.figure(figsize=(8,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf2a, annot=True, fmt=\".0f\",ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels', fontsize=15)\n",
    "ax.set_ylabel('Actual labels', fontsize=15)\n",
    "ax.set_title('Confusion Matrix (Decision Tree with TF/IDF)', fontsize=20)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "xgb_tv=DecisionTreeClassifier()\n",
    "\n",
    "#fitting the data to model\n",
    "xgb_tv.fit(tv_X_train,y_train)\n",
    "\n",
    "#prediction\n",
    "pred_xgb_tv=xgb_tv.predict(tv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb_tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "cv_score_xgb_tv= cross_val_score(xgb_tv,tv_X_train,y_train, cv=5)\n",
    "print(\"Accuracy: {}\" .format(np.mean(cv_score_xgb_tv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb Cell 93\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y161sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Classification report of Performance metrics\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y161sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m label\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mNeutral\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mPositive\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mNegative\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y161sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test,pred_xgb_tv))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "# Classification report of Performance metrics\n",
    "label=['Neutral','Positive','Negative']\n",
    "print(classification_report(y_test,pred_xgb_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confussion matrix\n",
    "cf3a= (confusion_matrix(y_test,pred_xgb_tv))\n",
    "plt.figure(figsize=(8,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf3a, annot=True, fmt=\".0f\",ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels', fontsize=15)\n",
    "ax.set_ylabel('Actual labels', fontsize=15)\n",
    "ax.set_title('Confusion Matrix (XG Boost with TF/IDF)', fontsize=20)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "knn = KNeighborsClassifier()\n",
    "param = {'n_neighbors': [1,2,3,4,5,6,7,8]}\n",
    "knn_tv = GridSearchCV(estimator=knn,param_grid=param)\n",
    "\n",
    "#fitting the data to model\n",
    "knn_tv.fit(tv_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted values\n",
    "pred_knn_tv = knn_cv.predict(tv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn_tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy_KNN_tv = accuracy_score(y_test,pred_knn_tv)\n",
    "print(\"Accuracy :\",(accuracy_KNN_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report of Performance metrics\n",
    "label=['Neutral','Positive','Negative']\n",
    "print(classification_report(y_test,pred_knn_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confussion matrix\n",
    "cf4a= (confusion_matrix(y_test,pred_xgb_tv))\n",
    "plt.figure(figsize=(8,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf4a, annot=True, fmt=\".0f\",ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels', fontsize=15)\n",
    "ax.set_ylabel('Actual labels', fontsize=15)\n",
    "ax.set_title('Confusion Matrix (KNN TF/IDF with GridsearchCV)', fontsize=20)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "svm_tv = SVC()\n",
    "\n",
    "#fitting the data to model\n",
    "svm_tv.fit(tv_X_train,y_train)\n",
    "\n",
    "#prediction\n",
    "pred_svm_tv = svm_tv.predict(tv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy_svm_tv = accuracy_score(y_test,pred_svm_tv)\n",
    "print(\"Accuracy :\",(accuracy_svm_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb Cell 104\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y205sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Classification report of Performance metrics\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y205sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m label\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mNeutral\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mPositive\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mNegative\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y205sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test,pred_svm_tv))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "# Classification report of Performance metrics\n",
    "label=['Neutral','Positive','Negative']\n",
    "print(classification_report(y_test,pred_svm_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb Cell 105\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y206sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Plotting Confussion matrix\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y206sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cf5a\u001b[39m=\u001b[39m (confusion_matrix(y_test,pred_svm_tv))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y206sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m5\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/soundarya/Desktop/Sentiment-Analysis-Covid-19/analysis.ipynb#Y206sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ax\u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplot()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "#Plotting Confussion matrix\n",
    "cf5a= (confusion_matrix(y_test,pred_svm_tv))\n",
    "plt.figure(figsize=(8,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf5a, annot=True, fmt=\".0f\",ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels', fontsize=15)\n",
    "ax.set_ylabel('Actual labels', fontsize=15)\n",
    "ax.set_title('Confusion Matrix (KNN TF/IDF with GridsearchCV)', fontsize=20)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's acurracy Score Comparision\n",
    "\n",
    "acurracy = {'Model':  ['Logistic Regression with GridserachCV', 'Decision Tree Classifier','XG-Boost Classifier','K-Nearest-Neighbours Classifier','Support-Vector-Machine Classifier'],\n",
    "        'Count Vector':  [accuracy_lr_cv,np.mean(cv_score_dt_cv),np.mean(cv_score_xgb_cv),accuracy_KNN,accuracy_svc],\n",
    "        'Tf/idf Vector': [accuracy_lr_Gcv,np.mean(cv_score_dt_tv),np.mean(cv_score_xgb_tv),accuracy_KNN_tv,accuracy_svm_tv]}\n",
    "\n",
    "cv_score_table= pd.DataFrame (acurracy, columns = ['Model','Count Vector','Tf/idf Vector'])\n",
    "\n",
    "cv_score_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
